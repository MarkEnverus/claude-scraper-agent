# ----------------------------------------------------------------------------
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml
#
# ----------------------------------------------------------------------------

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code using: baml-cli generate
# baml-cli is available with the baml package.

_file_map = {

    "ba_analyzer.baml": "// BAML Functions for BA Analyzer - 4-Phase Data Source Analysis\n// Based on ba-enhanced.md specification\n\n// ============================================================================\n// Phase 0: Data Source Type Detection\n// ============================================================================\n\nfunction AnalyzePhase0(\n    url: string,\n    html_content: string,\n    network_calls: string[]\n) -> Phase0Detection {\n    client ClaudeBedrock\n    prompt #\"\n        You are analyzing a data source to detect its type and discover API endpoints.\n\n        URL: {{ url }}\n\n        HTML Content:\n        {{ html_content }}\n\n        Network Calls Discovered:\n        {% for call in network_calls %}\n        - {{ call }}\n        {% endfor %}\n\n        Analyze the HTML and network traffic to determine:\n\n        1. Data Source Type:\n           - API: Look for REST endpoints, OpenAPI/Swagger docs, API documentation\n           - FTP: Look for ftp:// or sftp:// URLs, FTP/SFTP connection info\n           - WEBSITE: Look for download links to data files (.csv, .json, .xml, .xlsx, .zip)\n           - EMAIL: Look for subscribe forms, mailing list info, IMAP/SMTP config\n\n        2. Confidence Level (0.0 to 1.0):\n           - 0.9-1.0: Very clear indicators (multiple strong signals)\n           - 0.7-0.9: Clear indicators (at least 2 strong signals)\n           - 0.5-0.7: Some indicators (1-2 signals)\n           - 0.0-0.5: Unclear or mixed signals\n\n        3. Evidence Indicators:\n           List specific evidence found (e.g., \"Found 15 .csv download links\", \"OpenAPI spec visible\")\n\n        4. Discovered API Calls:\n           List all API endpoints found in network traffic (from network_calls parameter)\n           Include any /api/, /v1/, /data/, .json endpoints\n\n        5. Endpoints:\n           For each discovered endpoint, extract:\n           - path: Full URL path\n           - method: HTTP method (GET, POST, etc.)\n           - parameters: Empty list for Phase 0 (will be filled in Phase 1)\n           - auth_required: false for Phase 0 (will be determined in Phase 2)\n           - response_format: Guess based on URL (.json -> JSON, .xml -> XML, etc.)\n\n        IMPORTANT:\n        - If uncertain, default to WEBSITE (most flexible)\n        - Don't guess - only document what you actually see\n        - Network calls are the most reliable indicator for APIs\n\n        {{ ctx.output_format }}\n    \"#\n}\n\n// ============================================================================\n// Phase 1: Documentation/Metadata Extraction\n// ============================================================================\n\nfunction AnalyzePhase1(\n    url: string,\n    documentation_content: string,\n    phase0_result: Phase0Detection\n) -> Phase1Documentation {\n    client ClaudeBedrock\n    prompt #\"\n        You are analyzing documentation/metadata for a data source.\n\n        URL: {{ url }}\n        Detected Type: {{ phase0_result.detected_type }}\n\n        Documentation Content:\n        {{ documentation_content }}\n\n        {% if phase0_result.detected_type == \"API\" %}\n\n        For API data sources, extract:\n\n        1. Endpoint Discovery:\n           - Total endpoints found (must match actual count in endpoints array)\n           - Collapsible sections expanded (if applicable)\n           - Extraction method: \"puppeteer\" or \"webfetch\"\n           - Screenshot taken: true/false\n           - Systematic enumeration completed: true ONLY IF ALL of:\n             * All collapsible sections were expanded AND\n             * All visible endpoints were extracted AND\n             * Screenshot was taken showing expanded state\n             Otherwise set to false\n\n        2. Authentication Claims:\n           - Auth section found: true/false\n           - Auth section text: Exact text from docs (first 1000 chars)\n           - Signup links: All registration/signup URLs found\n           - API key mentioned: true/false\n           - Subscription mentioned: true/false\n           - Auth header examples: Code snippets showing auth headers\n           - Conclusion: Summary of auth requirements from docs\n\n        3. Endpoints (CRITICAL - NO HALLUCINATION):\n           For EACH endpoint visible in documentation:\n           - endpoint_id: Unique identifier (e.g., \"get-users\")\n           - path: Exact path from docs (e.g., \"/v1/users\")\n           - method: HTTP method (GET, POST, PUT, DELETE, PATCH)\n           - description: Description from docs\n           - parameters: List of parameters with name, type, required, description, example\n           - response_format: JSON, XML, CSV, HTML, BINARY\n           - authentication_mentioned: true if docs mention auth for this endpoint\n\n        4. Documentation Quality:\n           - EXCELLENT: Complete, clear, examples present\n           - HIGH: Clear with most details\n           - MEDIUM: Some details missing\n           - LOW: Minimal information\n           - POOR: Very unclear or contradictory\n\n        CRITICAL ANTI-HALLUCINATION RULES - ABSOLUTE PROHIBITION:\n        ❌ ONLY document endpoints you can ACTUALLY SEE in the documentation\n        ❌ DO NOT make up endpoints based on \"common patterns\"\n        ❌ DO NOT guess that \"/v1/data\" exists without seeing it in docs\n        ❌ If docs show 5 endpoints, document exactly 5 (not 10, not 3)\n        ❌ If uncertain if an endpoint exists, DO NOT include it\n        ✅ VERIFICATION: Before saving, ask: \"Did I see this EXACT endpoint path in the docs?\"\n\n        If you cannot find endpoint documentation, say so explicitly. Better to have 0 endpoints with high confidence than 10 hallucinated endpoints.\n\n        {% elif phase0_result.detected_type == \"WEBSITE\" %}\n\n        For WEBSITE data sources, extract:\n\n        1. Data Inventory:\n           - Total files discovered\n           - File formats: List of formats (csv, json, xml, xlsx, pdf, etc.)\n           - Categories: Data categories/sections found\n           - Download links: Array of links with url, text, fileType, fileSize, lastModified\n\n        2. Access Requirements:\n           - Authentication: \"none\", \"login_required\", \"api_key\", or \"unknown\"\n           - Registration: required (true/false), signup_links array\n           - Terms of use URL: Link to terms/legal page\n           - Subscription required: true/false\n           - Rate limits: Description or \"not_mentioned\"\n\n        3. Update Frequency:\n           Look for mentions of \"updated daily\", \"hourly\", \"weekly\", \"monthly\", \"real-time\"\n\n        4. Portal Type:\n           - STATIC: Traditional static HTML site\n           - SPA: Single-page application (JavaScript-rendered)\n           - API_DOCS: API documentation portal\n           - CUSTOM_FRAMEWORK: Custom framework\n\n        5. Extraction Quality:\n           - COMPREHENSIVE: All data sources documented\n           - PARTIAL: Some data sources documented\n           - LIMITED: Minimal extraction\n           - MISSING: Failed to extract meaningful data\n\n        {% else %}\n\n        For FTP/EMAIL data sources:\n        - Extract connection details, authentication requirements, data formats\n        - Document access instructions\n        - Note any scheduling or delivery information\n\n        {% endif %}\n\n        Notes: Any issues, warnings, or observations during extraction\n\n        {{ ctx.output_format }}\n    \"#\n}\n\n// ============================================================================\n// Phase 2: Portal Testing\n// ============================================================================\n\nfunction AnalyzePhase2(\n    url: string,\n    test_results_content: string,\n    phase0_result: Phase0Detection,\n    phase1_result: Phase1Documentation\n) -> Phase2Tests {\n    client ClaudeBedrock\n    prompt #\"\n        You are analyzing live test results for a data source.\n\n        URL: {{ url }}\n        Source Type: {{ phase0_result.detected_type }}\n\n        Test Results Content:\n        {{ test_results_content }}\n\n        {% if phase0_result.detected_type == \"API\" or phase1_result.endpoints|length > 0 %}\n\n        For API data sources, analyze test results:\n\n        1. Test Results:\n           For each test performed (no_auth, with_azure_apim_header, with_api_key_header, with_bearer):\n           - http_status: Actual HTTP status code from curl\n           - response_snippet: First 500 chars of response\n           - auth_keywords_found: Keywords like \"sign up\", \"api key\", \"authenticate\"\n           - full_output_file: Path to saved curl output file\n\n        2. Conclusion:\n           - auth_required: true/false based on test results\n           - evidence: Concrete evidence from testing (e.g., \"HTTP 404 + page contains 'sign up to acquire keys'\")\n           - likely_auth_method: NONE, API_KEY, BEARER_TOKEN, OAUTH, BASIC_AUTH, COOKIE, UNKNOWN\n           - likely_header_name: \"Ocp-Apim-Subscription-Key\", \"X-API-Key\", \"Authorization\", or null\n           - confidence: HIGH, MEDIUM, or LOW\n\n        TRUST TEST RESULTS OVER DOCUMENTATION:\n        - If docs say \"no auth\" but tests return 401/403/404 with auth mentions -> auth IS required\n        - If tests return 200 OK without auth -> no auth required\n        - HTTP 404 with auth keywords in response = auth required\n        - HTTP 401/403 = auth required\n\n        CRITICAL: FORBIDDEN CLAIMS BY HTTP STATUS\n        ✅ HTTP 200/201: Can claim \"API returns data\", \"No auth required\"\n        ✅ HTTP 401/403: Can claim \"Auth required\" | ❌ CANNOT claim \"No auth needed\"\n        ✅ HTTP 404: Can claim \"Endpoint not found\" | ❌ CANNOT claim \"API returns data\"\n\n        FORBIDDEN PHRASES (indicate hallucination):\n        ❌ \"Excellent! The API returned...\" (without HTTP 200)\n        ❌ \"Perfect! Let me analyze the response...\" (without reading file first)\n        ❌ \"The data shows...\" (without showing actual data)\n        ❌ \"Testing completed successfully\" (when status was 404)\n\n        TRUST THE TEST RESULTS OVER ASSUMPTIONS.\n\n        {% else %}\n\n        For WEBSITE data sources, analyze download tests:\n\n        1. Download Tests:\n           - total_links_tested: Number of links tested\n           - successful: Count of HTTP 200 responses\n           - failed: Count of non-200 responses\n           - results: Array of test results with:\n             * url: Link tested\n             * http_status: Status code\n             * content_type: Content-Type header\n             * content_length: Content-Length header\n             * last_modified: Last-Modified header\n             * accessible: true if HTTP 200\n             * requires_auth: true if HTTP 401/403\n             * redirect_to_login: true if redirected to login page\n\n        2. Authentication Findings:\n           - auth_required: true/false/partial\n           - evidence: Concrete evidence from tests\n           - cookie_required: true if cookie needed\n           - redirect_to_login: true if login redirect occurred\n           - auth_headers_found: WWW-Authenticate or other auth headers\n\n        3. File Metadata Verification:\n           - file_sizes_match_claims: \"true\", \"false\", or \"not_specified\"\n           - content_types_match: true/false\n           - last_modified_dates_available: true/false\n\n        Portal Conclusion: Summary of portal behavior and data access method\n\n        {% endif %}\n\n        Files Saved: List of all test output files saved during testing\n\n        {{ ctx.output_format }}\n    \"#\n}\n\n// ============================================================================\n// Phase 3: Specification Generation & Cross-Check Validation\n// ============================================================================\n\nfunction AnalyzePhase3(\n    url: string,\n    phase0: Phase0Detection,\n    phase1: Phase1Documentation,\n    phase2: Phase2Tests\n) -> ValidatedSpec {\n    client ClaudeBedrock\n    prompt #\"\n        You are generating a validated specification by cross-checking 3 phases of analysis.\n\n        URL: {{ url }}\n\n        Phase 0 Detection:\n        - Detected Type: {{ phase0.detected_type }}\n        - Confidence: {{ phase0.confidence }}\n\n        Phase 1 Documentation:\n        - Endpoints Found: {{ phase1.endpoints|length }}\n        - Doc Quality: {{ phase1.doc_quality }}\n        {% if phase1.auth_claims %}\n        - Auth Claims: {{ phase1.auth_claims.conclusion }}\n        {% endif %}\n\n        Phase 2 Testing:\n        {% if phase2.conclusion %}\n        - Auth Required: {{ phase2.conclusion.auth_required }}\n        - Evidence: {{ phase2.conclusion.evidence }}\n        {% endif %}\n\n        Generate a validated specification with:\n\n        1. Executive Summary (generate based on ALL phase data):\n           - total_endpoints_discovered: REQUIRED (int) - count all discovered endpoints\n           - accessible_endpoints: REQUIRED (int) - count endpoints that returned 200/201\n           - total_datasets: OPTIONAL - only for WEBSITE sources (int)\n           - total_files: OPTIONAL - only for WEBSITE sources (int)\n           - protected_endpoints: Count requiring authentication\n           - broken_endpoints: Count returning 404/errors\n           - success_rate: Percentage (e.g., \"85%\")\n           - primary_formats: List of formats (JSON, CSV, XML, etc.)\n           - authentication_required: true/false (TRUST PHASE 2)\n           - estimated_scraper_complexity: LOW, MEDIUM, or HIGH\n\n        2. Validation Summary:\n           - phases_completed: [\"Phase 0: Detection\", \"Phase 1: Documentation\", \"Phase 2: Testing\", \"Phase 3: Validation\"]\n           - documentation_review: \"completed\"\n           - live_api_testing: \"completed\" or \"not_applicable\"\n           - discrepancies_found: Count of discrepancies\n           - confidence_score: Calculate score (0.0-1.0):\n             * Start: 0.5\n             * +0.2 if phase1.doc_quality in [EXCELLENT, HIGH]\n             * +0.3 if phase2 tests completed successfully\n             * +0.2 if phase1 and phase2 agree on auth\n             * -0.1 per discrepancy\n             * Clamp to [0.0, 1.0]\n           - confidence_level: HIGH (>0.7), MEDIUM (0.5-0.7), LOW (<0.5)\n           - recommendation: \"Spec validated - ready for scraper generation\" if confidence >= 0.7\n\n        3. Authentication (TRUST PHASE 2 OVER PHASE 1):\n           - required: {{ phase2.conclusion.auth_required if phase2.conclusion else false }}\n           - method: {{ phase2.conclusion.likely_auth_method if phase2.conclusion else \"NONE\" }}\n           - header_name: {{ phase2.conclusion.likely_header_name if phase2.conclusion else null }}\n           - evidence: Evidence from Phase 2 testing\n           - registration_url: From Phase 1 signup links (first one)\n           - notes: \"Trust live API testing over documentation claims\"\n\n        4. Endpoints:\n           For EACH endpoint from Phase 1, create EndpointDetails with:\n           - endpoint_id: From Phase 1\n           - name: Descriptive name\n           - type: \"rest-api\", \"file-browser-api\", \"download\", etc.\n           - base_url: Base URL\n           - path: Endpoint path\n           - method: HTTP method\n           - parameters: Map of parameters from Phase 1\n           - authentication: Map with \"required\" and \"method\"\n           - response_format: From Phase 1\n           - data_structure: Optional structure description\n           - sample_files: Optional sample files (for WEBSITE sources)\n           - validation_status: Based on Phase 2 tests:\n             * TESTED_200_OK: HTTP 200\n             * TESTED_401_UNAUTHORIZED: HTTP 401\n             * TESTED_403_FORBIDDEN: HTTP 403\n             * TESTED_404_NOT_FOUND: HTTP 404\n             * NOT_TESTED: Not tested\n           - accessible: true if validation_status == TESTED_200_OK\n           - last_tested: ISO timestamp\n           - file_count: Optional file count\n           - update_frequency: From Phase 1\n           - notes: Any important notes\n\n        5. Scraper Recommendation:\n           - type: WEBSITE_PARSER, HTTP_COLLECTOR, API_CLIENT, or FTP_CLIENT\n           - rationale: List of reasons for this recommendation\n           - complexity: LOW, MEDIUM, or HIGH\n           - estimated_effort: \"2-4 hours\", \"1-2 days\", etc.\n           - key_challenges: List of challenges\n\n        6. Discrepancies:\n           Compare Phase 1 vs Phase 2 and identify mismatches:\n\n           Auth Requirement Mismatch:\n           - If Phase 1 says \"no auth\" but Phase 2 shows auth required\n           - Type: \"auth_requirement_mismatch\"\n           - Severity: \"high\"\n           - Resolution: \"Trust API testing - authentication IS required\"\n\n           Endpoint Validity:\n           - If Phase 2 returns 404 with no auth mentions\n           - Type: \"endpoint_not_found\"\n           - Severity: \"high\"\n           - Resolution: \"Verify endpoint URL is correct\"\n\n           Documentation Quality:\n           - If Phase 1 unclear but Phase 2 clear\n           - Type: \"documentation_quality\"\n           - Severity: \"medium\"\n           - Resolution: \"Documentation unclear but testing provides answer\"\n\n        7. Artifacts Generated:\n           List all files generated during analysis:\n           - datasource_analysis/phase0_detection.json\n           - datasource_analysis/phase1_documentation.json\n           - datasource_analysis/phase2_tests.json\n           - datasource_analysis/validated_datasource_spec.json\n           - Any test output files\n\n        8. Next Steps:\n           - \"Feed validated_datasource_spec.json to scraper-generator\"\n           - \"Register for API key at: [URL]\" (if auth required)\n           - \"Test with real credentials to confirm auth method\"\n           - Any other relevant steps\n\n        IMPORTANT:\n        - Always prefer Phase 2 (testing) over Phase 1 (documentation)\n        - Document ALL discrepancies explicitly\n        - Calculate confidence score based on consistency\n        - Be honest about limitations and gaps\n\n        {{ ctx.output_format }}\n    \"#\n}\n",
    "ba_collator.baml": "// BAML Functions for BA Collator Agent\n// Merges Run 1 and Run 2 analysis results with weighted confidence scoring\n\n// ============================================================================\n// Phase 0 Collation: Merge Detection Results\n// ============================================================================\n\nfunction MergePhase0(\n    run1: Phase0Detection,\n    run2: Phase0Detection,\n    run2_focus_areas: string[]\n) -> Phase0Detection {\n    client ClaudeBedrock\n    prompt #\"\n        You are merging two Phase 0 data source detection analysis runs.\n\n        ## Run 1 Result (30% weight - initial discovery):\n        {{ _.role(\"user\") }}\n        {{ run1 }}\n\n        ## Run 2 Result (70% weight - focused re-analysis):\n        {{ _.role(\"user\") }}\n        {{ run2 }}\n\n        ## Run 2 Focus Areas:\n        {{ _.role(\"user\") }}\n        {{ run2_focus_areas }}\n\n        ## Your Task: Merge the Detection Results\n\n        Apply these weighted merge rules:\n\n        1. **Detected Type**: If Run 2 has higher confidence, prefer Run 2's detection.\n           Otherwise, verify both agree.\n\n        2. **Confidence Score**: Calculate weighted average:\n           - Final confidence = (0.3 × Run1 confidence) + (0.7 × Run2 confidence)\n           - If both runs highly agree (difference < 0.1), add bonus +0.05 (max 1.0)\n\n        3. **Indicators**: Merge both lists, keeping unique indicators from both runs.\n           Run 2 indicators should be prioritized as they're from focused analysis.\n\n        4. **Discovered API Calls**: Combine all unique URLs/calls from both runs.\n           Deduplicate but preserve all discoveries.\n\n        5. **Endpoints**: Merge endpoint lists. If same endpoint appears in both runs,\n           prefer Run 2's details (higher weight).\n\n        6. **URL**: Should be identical in both runs. If different, prefer Run 2.\n\n        7. **Fallback Strategy**: Take from Run 2 if present, otherwise Run 1.\n\n        ## Output Requirements:\n\n        Return a merged Phase0Detection with:\n        - detected_type: The agreed-upon or highest-confidence type\n        - confidence: Weighted score (0.3 × run1 + 0.7 × run2)\n        - indicators: Combined unique indicators from both runs\n        - discovered_api_calls: All unique API calls from both runs\n        - endpoints: Merged endpoints (Run 2 preferred for conflicts)\n        - url: The data source URL\n        - fallback_strategy: From Run 2 if available\n\n        {{ ctx.output_format }}\n    \"#\n}\n\n// ============================================================================\n// Complete Spec Collation: Merge Validated Specifications\n// ============================================================================\n\nfunction MergeCompleteSpecs(\n    run1: ValidatedSpec,\n    run2: ValidatedSpec\n) -> ValidatedSpec {\n    client ClaudeBedrock\n    prompt #\"\n        You are merging two complete Business Analyst analysis runs into a final,\n        definitive data source specification.\n\n        ## Run 1 Specification (30% weight - initial analysis):\n        {{ _.role(\"user\") }}\n        {{ run1 }}\n\n        ## Run 2 Specification (70% weight - validator-guided focused analysis):\n        {{ _.role(\"user\") }}\n        {{ run2 }}\n\n        ## Your Task: Create the Final Merged Specification\n\n        Apply these weighted merge rules for each section:\n\n        ### 1. Executive Summary\n        - total_endpoints_discovered: Use Run 2 (should be most complete)\n        - accessible_endpoints: Use Run 2\n        - success_rate: Use Run 2\n        - primary_formats: Merge unique formats from both runs\n        - authentication_required: If runs disagree, prefer Run 2\n        - estimated_scraper_complexity: Use Run 2\n        - **NEW**: Add improvements_from_run1 field documenting what Run 2 improved\n\n        ### 2. Validation Summary\n        - phases_completed: Should be same for both\n        - confidence_score: Calculate using this formula:\n          1. Base weighted average: (0.3 × Run1 confidence) + (0.7 × Run2 confidence)\n          2. Consistency bonus: If |Run1 - Run2| < 0.1, add +0.05 (max 1.0)\n          3. Critical gaps deduction: If validation_report.critical_gaps_count > 0, subtract 0.1 (min 0.0)\n          Example: Run1=0.85, Run2=0.90, difference=0.05 → Base=0.885, +0.05 bonus = 0.935\n        - confidence_level: Based on final confidence (>0.8=HIGH, 0.6-0.8=MEDIUM, <0.6=LOW)\n        - discrepancies_found: Sum of unique discrepancies from both runs\n        - **NEW**: Add these collation fields:\n          - collation_complete: true\n          - runs_analyzed: 2\n          - final_confidence_score: <weighted average>\n          - run1_confidence: <from run1>\n          - run2_confidence: <from run2>\n          - confidence_consistency: \"improved\" | \"consistent\" | \"declined\"\n          - validator_status: \"pass\" | \"needs_improvement\" | \"fail\"\n          - discrepancies_resolved: <count of conflicts resolved>\n\n        ### 3. Endpoints List\n\n        Endpoint Matching Rules:\n        - Match endpoints by endpoint_id (primary key)\n        - If endpoint_id is same, consider it the same endpoint across runs\n        - For each Run 2 endpoint:\n          1. Find corresponding Run 1 endpoint by matching endpoint_id\n          2. If found: Mark tested_in_run1=true, tested_in_run2=true\n          3. If not found: Mark tested_in_run1=false, tested_in_run2=true\n        - For each Run 1 endpoint NOT in Run 2:\n          1. Add to final list with tested_in_run1=true, tested_in_run2=false\n          2. Add note: \"Found in Run 1 only - verify existence in next iteration\"\n\n        Endpoint Merging Process:\n        - Start with ALL endpoints from Run 2 (most comprehensive enumeration)\n        - For each Run 2 endpoint, check if it exists in Run 1:\n          - If yes: Mark tested_in_run1=true, tested_in_run2=true,\n            validation_consistency=<true if status matches>\n          - If no: Mark tested_in_run1=false, tested_in_run2=true,\n            validation_consistency=\"new_in_run2\"\n        - For any Run 1 endpoints NOT in Run 2 (shouldn't happen):\n          - Add with validation_consistency=\"missing_in_run2\"\n          - Add warning note\n\n        ### 4. Authentication & Access Requirements\n        - Prefer Run 2 values\n        - Add authentication_consistency: <bool> - do both runs agree?\n        - Add authentication_notes: Document if runs disagreed\n\n        ### 5. Data Catalog\n        - total_files_discovered: Use Run 2\n        - file_formats: Merge counts from both runs (prefer Run 2 for conflicts)\n        - data_categories: Unique categories from both runs\n        - downloadable_files: All unique files from both runs\n\n        ### 6. Scraper Recommendation\n        - Prefer Run 2 (more informed decision)\n        - Merge key_challenges from both runs\n\n        ### 7. Discrepancies\n        - Include discrepancies from BOTH runs\n        - Mark which run found each discrepancy\n\n        ### 8. Collation Metadata (NEW SECTION)\n        Add collation_metadata with:\n        - collation_timestamp: Current timestamp\n        - run1_timestamp: From run1.timestamp\n        - run2_timestamp: From run2.timestamp\n        - validation_report: \"datasource_analysis/ba_validation_report.json\"\n        - runs_compared: 2\n        - collation_agent: \"ba-collator\"\n\n        ### 9. Collation Analysis (NEW SECTION)\n        Add collation_analysis with:\n        - run_comparison: {\"endpoints_run1\": <count>, \"endpoints_run2\": <count>, ...}\n        - improvements_from_run2: List of specific improvements (e.g., \"Added 44 endpoints\")\n        - discrepancies_resolved: List of conflicts and how they were resolved\n        - consistency_checks: Map of areas checked and consistency results\n\n        ### 10. Artifacts & Next Steps\n        - artifacts_generated: Merge unique artifacts from both runs\n        - next_steps: Prefer Run 2's next steps (more complete picture)\n\n        ## Conflict Resolution Rules:\n\n        Apply these 5 rules IN ORDER:\n\n        **Rule 1 - Trust Run 2 for Enumeration:**\n        - Run 2's endpoint list is the PRIMARY source (validator-guided focused analysis)\n        - BUT preserve Run 1 endpoints with warning note if missing from Run 2\n        - Example: If Run 1 has endpoint X but Run 2 doesn't, include it with note: \"Found in Run 1 only - verify in next iteration\"\n\n        **Rule 2 - Trust Consistency:**\n        - If BOTH runs agree on a value → High confidence (add +0.05 bonus)\n        - If both agree on auth method, data format, endpoint accessibility → Keep shared value\n\n        **Rule 3 - Prefer Comprehensive Over Partial:**\n        - If Run 1 has incomplete data and Run 2 has complete → Use Run 2\n        - If Run 1 is PARTIAL and Run 2 is COMPLETE → Use Run 2\n\n        **Rule 4 - Include BOTH Values for Accessibility Claims:**\n        - If Run 1 says \"endpoint accessible\" and Run 2 says \"endpoint requires auth\":\n          * Include BOTH in auth_claims array\n          * Mark for verification\n          * Add note: \"Accessibility differs between runs - needs verification\"\n\n        **Rule 5 - Merge Testing Evidence:**\n        - ALWAYS preserve curl outputs from both runs\n        - Include test results from both passes\n        - Show what was tested in Run 1 vs Run 2\n\n        NEVER discard endpoints or testing evidence without investigation.\n\n        ## Output Requirements:\n\n        Return a complete ValidatedSpec that:\n        - Combines the best of both runs\n        - Documents improvements from Run 1 → Run 2\n        - Flags any inconsistencies or discrepancies\n        - Includes collation_metadata and collation_analysis sections\n        - Uses weighted confidence scoring throughout\n        - Clearly marks cross-run validation fields in endpoints\n\n        {{ ctx.output_format }}\n    \"#\n}\n",
    "ba_validator.baml": "// BAML Functions for BA Validator Agent\n// Validates BA analysis results for completeness and assigns confidence scores\n\n// ============================================================================\n// Phase 0 Validation Function\n// ============================================================================\n\nfunction ValidatePhase0(\n    phase0_result: Phase0Detection,\n    original_url: string\n) -> ValidationResult {\n    client ClaudeBedrock\n    prompt #\"\n        You are validating a Phase 0 data source detection result from a Business Analyst agent.\n\n        ## Phase 0 Result to Validate\n\n        - **Detected Type:** {{ phase0_result.detected_type }}\n        - **Confidence:** {{ phase0_result.confidence }}\n        - **Indicators:** {{ phase0_result.indicators }}\n        - **Discovered API Calls:** {{ phase0_result.discovered_api_calls }}\n        - **URL:** {{ original_url }}\n\n        ## Validation Criteria\n\n        Validate the following aspects:\n\n        1. **URL Validity**: Is {{ original_url }} a valid, well-formed URL with protocol (http/https/ftp/sftp)?\n        2. **Type Detection Plausibility**: Is the detected type ({{ phase0_result.detected_type }}) plausible given the URL format ({{ original_url }})?\n        3. **Indicator Sufficiency**: Are there enough indicators ({{ phase0_result.indicators | length }}) to support the detection?\n        4. **Endpoint Realism**: Are the discovered endpoints realistic and properly formatted?\n        5. **Confidence Justification**: Is the confidence score ({{ phase0_result.confidence }}) justified by the evidence?\n\n        ## Your Task\n\n        Analyze the Phase 0 results and identify:\n        - Any issues or inconsistencies\n        - Gaps in the analysis\n        - Areas that need more investigation in Run 2\n        - Whether the confidence score is appropriate\n\n        Provide specific, actionable recommendations for improving the analysis in a second run.\n\n        {{ ctx.output_format }}\n    \"#\n}\n\n// ============================================================================\n// Phase 1 Validation Function\n// ============================================================================\n\nfunction ValidatePhase1(\n    phase1_result: Phase1Documentation,\n    phase0_result: Phase0Detection\n) -> ValidationResult {\n    client ClaudeBedrock\n    prompt #\"\n        You are validating Phase 1 documentation extraction results.\n\n        ## Phase 1 Result to Validate\n\n        - **Source Type:** {{ phase1_result.source_type }}\n        - **Documentation Quality:** {{ phase1_result.doc_quality }}\n        - **Endpoints Found:** {{ phase1_result.endpoints | length }}\n        - **Extraction Quality:** {{ phase1_result.extraction_quality }}\n        - **Notes:** {{ phase1_result.notes }}\n\n        ## Phase 0 Context\n\n        - **Detected Type:** {{ phase0_result.detected_type }}\n        - **Expected Endpoints:** {{ phase0_result.discovered_api_calls | length }}\n\n        ## Validation Criteria\n\n        1. **Consistency with Phase 0**: Does Phase 1 source_type match Phase 0 detected_type?\n        2. **Endpoint Completeness**: Are all endpoints from Phase 0 documented in Phase 1?\n        3. **Extraction Quality**: Is extraction_quality acceptable? (COMPREHENSIVE is best, LIMITED/MISSING require improvement)\n        4. **Puppeteer Usage**: If extraction_quality is PARTIAL/LIMITED, was Puppeteer used? Should it be used in Run 2?\n        5. **Enumeration Completeness**: Are ALL discovered endpoints documented with full specifications?\n\n        Compare endpoint counts:\n        - Phase 0 discovered: {{ phase0_result.discovered_api_calls | length }} API calls\n        - Phase 1 documented: {{ phase1_result.endpoints | length }} endpoints\n        - If Phase 1 < Phase 0: Flag as \"incomplete_enumeration\" gap with HIGH severity\n        - Recommendation: \"Second pass must document all {{ phase0_result.discovered_api_calls | length }} discovered endpoints\"\n\n        ## Critical Checks\n\n        **For APIs:**\n        - Check if auth_claims exist and are complete\n        - Verify all endpoints have: path, method, parameters, response_format\n\n        **For Website Portals:**\n        - Check if data_inventory exists and has file counts\n        - Verify access_requirements are documented\n\n        ## Red Flags\n\n        - Only 2-3 endpoints documented when Phase 0 found 10+\n        - extraction_quality is PARTIAL/LIMITED without explanation\n        - No mention of Puppeteer usage for JavaScript-rendered sites\n        - Missing auth claims for APIs\n        - Incomplete endpoint specifications\n\n        {{ ctx.output_format }}\n    \"#\n}\n\n// ============================================================================\n// Phase 2 Validation Function\n// ============================================================================\n\nfunction ValidatePhase2(\n    phase2_result: Phase2Tests,\n    phase1_result: Phase1Documentation\n) -> ValidationResult {\n    client ClaudeBedrock\n    prompt #\"\n        You are validating Phase 2 live testing results.\n\n        ## Phase 2 Result to Validate\n\n        - **Source Type:** {{ phase2_result.source_type }}\n        - **Endpoint Tested:** {{ phase2_result.endpoint_tested }}\n        - **Files Saved:** {{ phase2_result.files_saved | length }} files\n        - **Conclusion:** {{ phase2_result.conclusion }}\n\n        ## Phase 1 Context\n\n        - **Documentation Claims:** {{ phase1_result.auth_claims }}\n        - **Endpoints Documented:** {{ phase1_result.endpoints | length }}\n\n        ## Validation Criteria\n\n        1. **Evidence-Based Testing**: Are test results based on actual HTTP requests with saved outputs?\n        2. **Authentication Validation**: Do test results confirm or contradict Phase 1 auth claims?\n        3. **File Artifacts**: Are all test outputs saved to disk for verification?\n        4. **Completeness**: Were enough endpoints tested to validate the analysis?\n\n        ## Critical Checks\n\n        **For APIs:**\n        - Check if test_results contain actual HTTP status codes (200, 401, 403, 404)\n        - Verify auth_keywords_found is populated with real evidence\n        - Ensure full_output_file paths exist for each test\n\n        **For Website Portals:**\n        - Check if download_tests cover representative samples\n        - Verify accessibility status for each tested link\n        - Ensure authentication findings are evidence-based\n\n        ## Red Flags\n\n        - No files_saved (indicates tests may not have actually run)\n        - HTTP 404 but conclusion says \"no auth required\"\n        - High confidence but no test artifacts\n        - Contradictions between Phase 1 and Phase 2 not explained\n\n        {{ ctx.output_format }}\n    \"#\n}\n\n// ============================================================================\n// Complete Specification Validation Function\n// ============================================================================\n\nfunction ValidateCompleteSpec(\n    spec: ValidatedSpec\n) -> ValidationReport {\n    client ClaudeBedrock\n    prompt #\"\n        You are validating a complete data source specification from the BA agent.\n\n        ## Specification to Validate\n\n        **Executive Summary:**\n        - Total endpoints discovered: {{ spec.executive_summary.total_endpoints_discovered }}\n        - Accessible endpoints: {{ spec.executive_summary.accessible_endpoints }}\n        - Success rate: {{ spec.executive_summary.success_rate }}\n        - Authentication required: {{ spec.executive_summary.authentication_required }}\n\n        **Validation Summary:**\n        - Confidence score: {{ spec.validation_summary.confidence_score }}\n        - Confidence level: {{ spec.validation_summary.confidence_level }}\n        - Discrepancies found: {{ spec.validation_summary.discrepancies_found }}\n\n        **Endpoints:**\n        - Total documented: {{ spec.endpoints | length }}\n\n        ## Validation Tasks\n\n        ### 1. Endpoint Enumeration Completeness\n\n        **CRITICAL**: Verify that ALL discovered endpoints are fully documented.\n\n        Compare:\n        - Executive summary claims: {{ spec.executive_summary.total_endpoints_discovered }} endpoints\n        - Actually documented: {{ spec.endpoints | length }} endpoints\n\n        **If mismatch detected:**\n        - Severity: CRITICAL\n        - Gap type: incomplete_enumeration\n        - Action: Second pass MUST enumerate ALL endpoints\n\n        ### 2. Confidence Score Validation\n\n        Check if confidence score ({{ spec.validation_summary.confidence_score }}) is justified:\n        - High confidence (>0.8) but many endpoints missing → INCONSISTENT\n        - High confidence but extraction_quality is PARTIAL → INCONSISTENT\n        - Low confidence but comprehensive analysis → May be overly conservative\n\n        ### 3. Puppeteer Usage Check\n\n        NOTE: This check is performed in ValidatePhase1 function, NOT here in ValidateCompleteSpec.\n        The complete spec doesn't include phase1_result, so Puppeteer validation happens earlier.\n\n        For website portals or JavaScript-rendered sites (checked in Phase 1 validation):\n        - Check artifacts_generated for evidence of Puppeteer usage\n        - If extraction_quality is PARTIAL/LIMITED → Puppeteer should have been used\n        - If not used → Recommend for Run 2\n\n        ### 4. Cross-Phase Consistency\n\n        Verify consistency across phases:\n        - Do authentication findings match across Phase 1 and Phase 2?\n        - Are discrepancies properly documented and resolved?\n        - Is the confidence score consistent with the quality of evidence?\n\n        ### 5. Scraper Recommendation Validity\n\n        Check if scraper_recommendation is appropriate:\n        - Type matches source_type?\n        - Complexity assessment is reasonable?\n        - Key challenges are specific and actionable?\n\n        ## Output Requirements\n\n        Generate a comprehensive validation report with:\n\n        1. **Overall Status**: PASS, NEEDS_IMPROVEMENT, or FAIL\n        2. **Overall Confidence**: Your assessment of spec quality (0.0-1.0)\n        3. **Phase Validations**: Status and issues for each phase\n        4. **Critical Gaps**: List of critical issues that MUST be addressed\n        5. **Recommendations**: Specific actions for Run 2 (if needed)\n\n        ## Confidence Threshold\n\n        - If overall_confidence < 0.8 → Recommend Run 2\n        - If overall_confidence >= 0.8 → Spec is acceptable, Run 2 optional\n\n        {{ ctx.output_format }}\n    \"#\n}\n\n// ============================================================================\n// Validation Result Type (defined in types.baml)\n// ============================================================================\n",
    "clients.baml": "// BAML Client Configurations for Scraper Agent Architecture\n\n// ============================================================================\n// AWS Bedrock Client (Primary for Production)\n// ============================================================================\n\nclient<llm> ClaudeBedrock {\n  provider aws-bedrock\n  retry_policy DefaultRetry\n  options {\n    model \"us.anthropic.claude-sonnet-4-5-20250929-v1:0\"\n    region \"us-east-1\"\n    // max_tokens: Not supported in BAML 0.214.0 client options\n    // Token limits must be configured in the runtime invocation\n    // AWS credentials are read from environment variables:\n    // AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_SESSION_TOKEN (optional)\n  }\n}\n\n// ============================================================================\n// Anthropic API Client (Alternative/Development)\n// ============================================================================\n\nclient<llm> ClaudeAnthropic {\n  provider anthropic\n  retry_policy DefaultRetry\n  options {\n    model \"claude-sonnet-4-5-20251101\"\n    // max_tokens: Not supported in BAML 0.214.0 client options\n    // Token limits must be configured in the runtime invocation\n    // API key is read from ANTHROPIC_API_KEY environment variable\n  }\n}\n\n// ============================================================================\n// Retry Policy for All Clients\n// ============================================================================\n\nretry_policy DefaultRetry {\n  max_retries 3\n  strategy {\n    type exponential_backoff\n  }\n}\n",
    "generator.baml": "// BAML Generator Configuration\n\ngenerator python_client {\n  output_type \"python/pydantic\"\n  output_dir \"../baml_client\"\n  version \"0.214.0\"\n}\n",
    "scraper_generator.baml": "// BAML Functions for Scraper Code Generation\n// Generates Python code for complex scraper logic that cannot be templated\n\n// ============================================================================\n// Code Generation Types\n// ============================================================================\n\nclass GeneratedCode {\n    code string @description(\"Generated Python code\")\n    imports string[] @description(\"Required imports (if any additional needed)\")\n    notes string @description(\"Implementation notes or warnings\")\n}\n\nclass ValidationRules {\n    required_fields string[] @description(\"Fields that must be present\")\n    format_checks string[] @description(\"Format validation checks\")\n    range_checks string[] @description(\"Value range validations\")\n    custom_logic string @description(\"Custom validation logic description\")\n}\n\n// ============================================================================\n// Generate collect_content() Method Body\n// ============================================================================\n\nfunction GenerateCollectContent(\n    ba_spec_json: string,\n    endpoint: string,\n    auth_method: string,\n    data_format: string,\n    timeout_seconds: int,\n    retry_attempts: int\n) -> GeneratedCode {\n    client ClaudeBedrock\n    prompt #\"\n        You are generating the Python implementation for a collect_content() method\n        in a data collector class that inherits from BaseCollector.\n\n        BA Analyzer Spec (JSON):\n        {{ ba_spec_json }}\n\n        Endpoint: {{ endpoint }}\n        Authentication: {{ auth_method }}\n        Data Format: {{ data_format }}\n        Timeout: {{ timeout_seconds }} seconds\n        Retry Attempts: {{ retry_attempts }}\n\n        Generate the METHOD BODY ONLY (not the method signature) for:\n\n        ```python\n        def collect_content(self, candidate: DownloadCandidate) -> CollectedContent:\n            # YOUR GENERATED CODE HERE\n        ```\n\n        Requirements:\n\n        1. HTTP Request Logic:\n           - Use requests library with proper error handling\n           - Include retry logic with exponential backoff\n           - Handle timeouts correctly\n           - Log each attempt\n\n        2. Authentication:\n           {% if auth_method == \"API_KEY\" or auth_method == \"BEARER_TOKEN\" or auth_method == \"BASIC_AUTH\" %}\n           - Use self.auth_headers (already set up in __init__)\n           - Pass headers to requests.get()\n           {% elif auth_method == \"OAUTH\" %}\n           - Implement OAuth token exchange if needed\n           - Refresh token handling\n           {% elif auth_method == \"NONE\" %}\n           - No authentication headers needed\n           {% else %}\n           - Custom authentication logic as described in BA spec\n           {% endif %}\n\n        3. Response Processing:\n           {% if data_format == \"json\" %}\n           - Parse JSON with error handling\n           - Validate JSON structure\n           - Extract relevant data\n           {% elif data_format == \"csv\" %}\n           - Read CSV content\n           - Validate CSV structure\n           {% elif data_format == \"xml\" %}\n           - Parse XML with error handling\n           - Validate XML structure\n           {% else %}\n           - Handle binary/text content appropriately\n           {% endif %}\n\n        4. Error Handling:\n           - Try-except blocks for HTTP errors\n           - Try-except blocks for parsing errors\n           - Log errors with context\n           - Return CollectedContent with success=False on errors\n\n        5. Return Value:\n           Return CollectedContent(\n               candidate=candidate,\n               success=True/False,\n               content=bytes,  # Raw content\n               content_hash=computed_hash,\n               error_message=None or error string,\n               metadata={...}  # Any additional metadata\n           )\n\n        6. Code Style:\n           - Use existing logger instance (logger.info, logger.error)\n           - Follow PEP 8 style\n           - Add inline comments for complex logic\n           - Use type hints\n           - Handle edge cases\n\n        IMPORTANT:\n        - Generate ONLY the method body (the code inside the function)\n        - Do NOT include the method signature \"def collect_content(...):\"\n        - Do NOT include docstring (template already has it)\n        - Assume self.base_url, self.auth_headers, self.timeout, self.retry_attempts exist\n        - Assume imports: requests, logging, hashlib, json\n        - Use 4-space indentation\n        - End with return statement\n\n        Example structure:\n        ```python\n        url = candidate.url\n        headers = self.auth_headers.copy()\n\n        for attempt in range(self.retry_attempts):\n            try:\n                response = requests.get(\n                    url,\n                    headers=headers,\n                    timeout=self.timeout,\n                )\n                response.raise_for_status()\n\n                # Parse content\n                content = response.content\n                content_hash = hashlib.sha256(content).hexdigest()\n\n                logger.info(f\"Successfully collected content from {url}\")\n\n                return CollectedContent(\n                    candidate=candidate,\n                    success=True,\n                    content=content,\n                    content_hash=content_hash,\n                )\n\n            except requests.RequestException as e:\n                logger.warning(f\"Attempt {attempt + 1} failed: {e}\")\n                if attempt == self.retry_attempts - 1:\n                    return CollectedContent(\n                        candidate=candidate,\n                        success=False,\n                        error_message=str(e),\n                    )\n                time.sleep(2 ** attempt)  # Exponential backoff\n        ```\n\n        {{ ctx.output_format }}\n    \"#\n}\n\n// ============================================================================\n// Generate validate_content() Method Body\n// ============================================================================\n\nfunction GenerateValidateContent(\n    ba_spec_json: string,\n    endpoint: string,\n    data_format: string,\n    validation_requirements: string\n) -> GeneratedCode {\n    client ClaudeBedrock\n    prompt #\"\n        You are generating the Python implementation for a validate_content() method\n        in a data collector class that inherits from BaseCollector.\n\n        BA Analyzer Spec (JSON):\n        {{ ba_spec_json }}\n\n        Endpoint: {{ endpoint }}\n        Data Format: {{ data_format }}\n        Validation Requirements: {{ validation_requirements }}\n\n        Generate the METHOD BODY ONLY for:\n\n        ```python\n        def validate_content(self, content: CollectedContent) -> ValidationResult:\n            # YOUR GENERATED CODE HERE\n        ```\n\n        Requirements:\n\n        1. Basic Validations (Always Include):\n           - Check content is not empty\n           - Check content is not None\n           - Verify content size is reasonable (not 0 bytes, not > 100MB)\n\n        2. Format-Specific Validations:\n           {% if data_format == \"json\" %}\n           JSON Validation:\n           - Verify valid JSON syntax (json.loads)\n           - Check required top-level keys exist\n           - Validate data types of key fields\n           - Check for expected structure (arrays, objects)\n           - Verify data array is not empty\n           {% elif data_format == \"csv\" %}\n           CSV Validation:\n           - Verify CSV can be parsed\n           - Check header row exists\n           - Validate column names match expected\n           - Check minimum number of rows\n           - Verify data types in key columns\n           {% elif data_format == \"xml\" %}\n           XML Validation:\n           - Verify valid XML syntax\n           - Check root element is correct\n           - Validate required elements exist\n           - Check namespaces if applicable\n           {% else %}\n           Generic Validation:\n           - Check content type matches expected\n           - Verify minimum size requirements\n           - Check for error indicators in content\n           {% endif %}\n\n        3. Business Logic Validations (Based on BA Spec):\n           - Timestamp/date fields are valid ISO8601\n           - Numeric fields are in expected ranges\n           - Required fields are present\n           - Data consistency checks\n\n        4. Return Value:\n           - Return ValidationResult with:\n             * is_valid: True/False\n             * errors: List of error messages (empty if valid)\n             * warnings: List of warnings (non-critical issues)\n             * metadata: Dict with validation stats\n\n        5. Error Handling:\n           - Try-except for parsing errors\n           - Collect ALL validation errors (don't fail on first)\n           - Log validation issues\n           - Clear error messages\n\n        6. Code Style:\n           - Use existing logger\n           - Follow PEP 8\n           - Type hints\n           - Inline comments\n\n        IMPORTANT:\n        - Generate ONLY the method body\n        - Do NOT include method signature or docstring\n        - Assume content.content is bytes\n        - Assume content.success is bool\n        - Use 4-space indentation\n        - Return ValidationResult at the end\n\n        Example structure:\n        ```python\n        errors = []\n        warnings = []\n\n        # Check if collection succeeded\n        if not content.success:\n            errors.append(\"Content collection failed\")\n            return ValidationResult(\n                is_valid=False,\n                errors=errors,\n                warnings=warnings,\n            )\n\n        # Check content exists\n        if not content.content:\n            errors.append(\"Content is empty\")\n            return ValidationResult(\n                is_valid=False,\n                errors=errors,\n                warnings=warnings,\n            )\n\n        # Parse and validate format\n        try:\n            data = json.loads(content.content)\n\n            # Check required fields\n            if \"data\" not in data:\n                errors.append(\"Missing 'data' field in JSON\")\n\n            # Validate data array\n            if \"data\" in data:\n                if not isinstance(data[\"data\"], list):\n                    errors.append(\"'data' field must be an array\")\n                elif len(data[\"data\"]) == 0:\n                    warnings.append(\"'data' array is empty\")\n\n        except json.JSONDecodeError as e:\n            errors.append(f\"Invalid JSON: {e}\")\n\n        # Return result\n        is_valid = len(errors) == 0\n\n        logger.info(\n            f\"Validation {'passed' if is_valid else 'failed'}\",\n            extra={\n                \"errors\": len(errors),\n                \"warnings\": len(warnings),\n            },\n        )\n\n        return ValidationResult(\n            is_valid=is_valid,\n            errors=errors,\n            warnings=warnings,\n            metadata={\"content_size\": len(content.content)},\n        )\n        ```\n\n        {{ ctx.output_format }}\n    \"#\n}\n\n// ============================================================================\n// Generate Complex Authentication Logic\n// ============================================================================\n\nfunction GenerateComplexAuth(\n    auth_spec: string,\n    auth_method: string,\n    registration_url: string\n) -> GeneratedCode {\n    client ClaudeBedrock\n    prompt #\"\n        You are generating Python code for complex authentication setup.\n\n        Authentication Spec:\n        {{ auth_spec }}\n\n        Auth Method: {{ auth_method }}\n        Registration URL: {{ registration_url }}\n\n        This code will be inserted into the _init_auth() method of a collector class.\n\n        Generate authentication setup code for:\n\n        {% if auth_method == \"OAUTH\" %}\n        OAuth Authentication:\n        - Token endpoint configuration\n        - Client ID/secret handling\n        - Token exchange flow\n        - Token refresh logic\n        - Store token in self.auth_headers\n        {% elif auth_method == \"SAML\" %}\n        SAML Authentication:\n        - SAML endpoint configuration\n        - Certificate handling\n        - Assertion generation\n        - Token extraction\n        {% elif auth_method == \"COOKIE\" %}\n        Cookie-Based Authentication:\n        - Login request setup\n        - Session cookie extraction\n        - Cookie storage for requests\n        {% elif auth_method == \"MFA\" %}\n        Multi-Factor Authentication:\n        - Initial login request\n        - MFA challenge handling\n        - Token verification\n        - Final authentication\n        {% else %}\n        Custom Authentication:\n        - Parse auth_spec for requirements\n        - Implement described authentication flow\n        - Handle credentials securely\n        {% endif %}\n\n        Requirements:\n\n        1. Credential Handling:\n           - Read from environment variables (never hardcode)\n           - Validate credentials exist\n           - Raise clear error if missing\n\n        2. Token Management (if applicable):\n           - Request token from auth endpoint\n           - Parse token from response\n           - Store token in self.auth_headers\n           - Handle token expiration\n           - Implement token refresh\n\n        3. Error Handling:\n           - Try-except for auth requests\n           - Clear error messages\n           - Log authentication attempts\n           - Raise ValueError on auth failure\n\n        4. Security:\n           - Never log credentials\n           - Use HTTPS for auth requests\n           - Validate SSL certificates\n           - Use secure token storage\n\n        5. Code Style:\n           - Use existing logger\n           - Follow PEP 8\n           - Type hints\n           - Inline comments\n\n        IMPORTANT:\n        - Generate code that will be inserted into _init_auth() method\n        - Assume self.api_key exists (from __init__ parameter)\n        - Set self.auth_headers = {...} at the end\n        - Use 4-space indentation\n        - Import any additional libraries needed (add to imports list)\n\n        Example for OAuth:\n        ```python\n        # OAuth token endpoint\n        token_url = \"https://auth.example.com/oauth/token\"\n\n        # Request access token\n        try:\n            response = requests.post(\n                token_url,\n                data={\n                    \"grant_type\": \"client_credentials\",\n                    \"client_id\": self.api_key.split(\":\")[0],\n                    \"client_secret\": self.api_key.split(\":\")[1],\n                },\n                timeout=30,\n            )\n            response.raise_for_status()\n\n            token_data = response.json()\n            access_token = token_data[\"access_token\"]\n\n            # Store in auth headers\n            self.auth_headers = {\n                \"Authorization\": f\"Bearer {access_token}\",\n            }\n\n            logger.info(\"OAuth authentication successful\")\n\n        except requests.RequestException as e:\n            raise ValueError(f\"OAuth authentication failed: {e}\")\n        except (KeyError, json.JSONDecodeError) as e:\n            raise ValueError(f\"Failed to parse OAuth token: {e}\")\n        ```\n\n        {{ ctx.output_format }}\n    \"#\n}\n\n// ============================================================================\n// Generate Custom __init__ Logic\n// ============================================================================\n\nfunction GenerateInitCode(\n    ba_spec_json: string,\n    custom_requirements: string\n) -> GeneratedCode {\n    client ClaudeBedrock\n    prompt #\"\n        You are generating custom initialization code for a collector class.\n\n        BA Analyzer Spec (JSON):\n        {{ ba_spec_json }}\n\n        Custom Requirements:\n        {{ custom_requirements }}\n\n        Generate additional initialization code that will be inserted at the END\n        of the __init__ method, after standard initialization.\n\n        Use cases:\n        - Setting up custom clients (Selenium, Playwright, FTP, SMTP)\n        - Initializing complex data structures\n        - Pre-loading configuration\n        - Setting up connection pools\n\n        Requirements:\n\n        1. Custom Client Setup:\n           - Initialize any special clients (Selenium, Playwright)\n           - Configure client options\n           - Store client as self attribute\n           - Handle initialization errors\n\n        2. Configuration Loading:\n           - Load any additional config files\n           - Parse custom settings\n           - Validate configuration\n           - Set default values\n\n        3. Resource Initialization:\n           - Set up connection pools\n           - Initialize caches\n           - Prepare data structures\n\n        4. Error Handling:\n           - Try-except for setup errors\n           - Clear error messages\n           - Log initialization steps\n\n        5. Code Style:\n           - Use existing logger\n           - Follow PEP 8\n           - Type hints\n           - Inline comments\n\n        IMPORTANT:\n        - Generate code that will be added to __init__ method\n        - Assume standard __init__ parameters already exist\n        - Use self.attribute_name for new attributes\n        - Use 4-space indentation\n        - Import any additional libraries (add to imports list)\n\n        Example for Selenium setup:\n        ```python\n        # Initialize Selenium WebDriver for JavaScript rendering\n        from selenium import webdriver\n        from selenium.webdriver.chrome.options import Options\n\n        chrome_options = Options()\n        chrome_options.add_argument(\"--headless\")\n        chrome_options.add_argument(\"--no-sandbox\")\n        chrome_options.add_argument(\"--disable-dev-shm-usage\")\n\n        try:\n            self.driver = webdriver.Chrome(options=chrome_options)\n            logger.info(\"Selenium WebDriver initialized\")\n        except Exception as e:\n            logger.warning(f\"Failed to initialize Selenium: {e}\")\n            self.driver = None\n        ```\n\n        {{ ctx.output_format }}\n    \"#\n}\n",
    "types.baml": "// BAML Type Definitions for Scraper Agent Architecture\n// Generated from ba-enhanced.md, ba-validator.md, ba-collator.md specifications\n\n// ============================================================================\n// Enums\n// ============================================================================\n\nenum DataSourceType {\n  API\n  FTP\n  WEBSITE\n  EMAIL\n}\n\nenum HTTPMethod {\n  GET\n  POST\n  PUT\n  DELETE\n  PATCH\n  HEAD\n  OPTIONS\n}\n\nenum AuthenticationMethod {\n  NONE\n  API_KEY\n  BEARER_TOKEN\n  OAUTH\n  BASIC_AUTH\n  COOKIE\n  UNKNOWN\n}\n\nenum ValidationStatus {\n  TESTED_200_OK\n  TESTED_401_UNAUTHORIZED\n  TESTED_403_FORBIDDEN\n  TESTED_404_NOT_FOUND\n  NOT_TESTED\n}\n\nenum ExtractionQuality {\n  COMPREHENSIVE\n  PARTIAL\n  LIMITED\n  MISSING\n}\n\nenum ConfidenceLevel {\n  HIGH\n  MEDIUM\n  LOW\n}\n\nenum DocQuality {\n  EXCELLENT\n  HIGH\n  MEDIUM\n  LOW\n  POOR\n}\n\nenum PortalType {\n  STATIC\n  SPA\n  API_DOCS\n  CUSTOM_FRAMEWORK\n}\n\nenum ResponseFormat {\n  JSON\n  XML\n  CSV\n  HTML\n  BINARY\n}\n\nenum ParameterLocation {\n  PATH\n  QUERY\n  HEADER\n  BODY\n  COOKIE\n  MATRIX\n}\n\nenum ValidationOverallStatus {\n  PASS\n  NEEDS_IMPROVEMENT\n  FAIL\n}\n\nenum ScraperType {\n  WEBSITE_PARSER\n  HTTP_COLLECTOR\n  API_CLIENT\n  FTP_CLIENT\n}\n\nenum ComplexityLevel {\n  LOW\n  MEDIUM\n  HIGH\n}\n\n// ============================================================================\n// Parameter and Endpoint Types\n// ============================================================================\n\nclass Parameter {\n  name string\n  type string\n  required bool\n  description string\n  example string?\n}\n\nclass Endpoint {\n  path string\n  method HTTPMethod @description(\"HTTP method: GET, POST, PUT, PATCH, DELETE\")\n  parameters Parameter[]\n  auth_required bool\n  response_format ResponseFormat\n}\n\nclass EndpointDetails {\n  endpoint_id string\n  name string\n  type string\n  base_url string\n  path string\n  method HTTPMethod\n  parameters map<string, Parameter>\n  authentication map<string, string>\n  response_format ResponseFormat\n  data_structure map<string, string>?\n  sample_files map<string, string>[]?\n  validation_status ValidationStatus\n  accessible bool\n  last_tested string\n  file_count int?\n  update_frequency string?\n  notes string\n  // Cross-run validation fields\n  validation_consistency string?\n  tested_in_run1 bool?\n  tested_in_run2 bool?\n}\n\n// ============================================================================\n// Phase 0: Detection Types\n// ============================================================================\n\nclass Phase0Detection {\n  detected_type DataSourceType\n  confidence float @description(\"Confidence score between 0.0 and 1.0 (validated: must be >= 0.0 and <= 1.0)\")\n  indicators string[]\n  discovered_api_calls string[] @description(\"List of discovered API endpoints or calls\")\n  endpoints Endpoint[]\n  url string\n  fallback_strategy string?\n}\n\n// ============================================================================\n// Phase 1: Documentation Types\n// ============================================================================\n\nclass EndpointDiscovery {\n  total_endpoints_found int\n  collapsible_sections_expanded int\n  extraction_method string\n  screenshot_taken bool\n  systematic_enumeration_completed bool\n}\n\nclass AuthClaims {\n  auth_section_found bool\n  auth_section_text string?\n  signup_links string[]\n  api_key_mentioned bool\n  subscription_mentioned bool\n  auth_header_examples string[]\n  conclusion string\n}\n\nclass EndpointSpec {\n  endpoint_id string\n  path string\n  method HTTPMethod\n  description string\n  parameters Parameter[]\n  response_format ResponseFormat\n  authentication_mentioned bool\n}\n\nclass DataInventory {\n  total_files int\n  file_formats string[]\n  categories string[]\n  download_links map<string, string>[]\n}\n\nclass AccessRequirements {\n  authentication string\n  registration map<string, string>?\n  terms_of_use_url string?\n  subscription_required bool\n  rate_limits string\n}\n\nclass Phase1Documentation {\n  source string\n  timestamp string\n  url string\n  endpoint_discovery EndpointDiscovery?\n  auth_claims AuthClaims?\n  endpoints EndpointSpec[]\n  doc_quality DocQuality\n  notes string\n  // For website portals\n  source_type string?\n  data_inventory DataInventory?\n  access_requirements AccessRequirements?\n  update_frequency string?\n  portal_type PortalType?\n  extraction_quality ExtractionQuality?\n}\n\n// ============================================================================\n// Phase 2: Testing Types\n// ============================================================================\n\nclass TestResult {\n  http_status int\n  response_snippet string\n  auth_keywords_found string[]\n  full_output_file string\n}\n\nclass TestConclusion {\n  auth_required bool\n  evidence string\n  likely_auth_method AuthenticationMethod\n  likely_header_name string?\n  confidence ConfidenceLevel\n}\n\nclass DownloadTest {\n  url string\n  http_status int\n  content_type string?\n  content_length string?\n  last_modified string?\n  accessible bool\n  requires_auth bool\n  redirect_to_login bool?\n}\n\nclass AuthenticationFindings {\n  auth_required bool\n  evidence string\n  cookie_required bool\n  redirect_to_login bool\n  auth_headers_found string[]\n}\n\nclass FileMetadataVerification {\n  file_sizes_match_claims string\n  content_types_match bool\n  last_modified_dates_available bool\n}\n\nclass Phase2Tests {\n  source string\n  timestamp string\n  endpoint_tested string?\n  test_results map<string, TestResult>?\n  conclusion TestConclusion?\n  files_saved string[]\n  // For website portals\n  source_type string?\n  download_tests map<string, DownloadTest[]>?\n  authentication_findings AuthenticationFindings?\n  file_metadata_verification FileMetadataVerification?\n  portal_type PortalType?\n  portal_conclusion string? @description(\"Summary of portal behavior and data access method (only for website portals)\")\n}\n\n// ============================================================================\n// Phase 3: Validated Spec Types\n// ============================================================================\n\nclass ValidationSummary {\n  phases_completed string[]\n  documentation_review string\n  live_api_testing string\n  discrepancies_found int\n  confidence_score float @description(\"Confidence score between 0.0 and 1.0 (validated: must be >= 0.0 and <= 1.0)\")\n  confidence_level ConfidenceLevel\n  recommendation string\n  // Additional fields\n  collation_complete bool?\n  runs_analyzed int?\n  final_confidence_score float? @description(\"Final confidence between 0.0 and 1.0 (validated: must be >= 0.0 and <= 1.0)\")\n  run1_confidence float? @description(\"Run 1 confidence between 0.0 and 1.0 (validated: must be >= 0.0 and <= 1.0)\")\n  run2_confidence float? @description(\"Run 2 confidence between 0.0 and 1.0 (validated: must be >= 0.0 and <= 1.0)\")\n  confidence_consistency string?\n  validator_status string?\n  discrepancies_resolved int?\n}\n\nclass AuthenticationSpec {\n  required bool\n  method AuthenticationMethod\n  header_name string?\n  evidence string\n  registration_url string?\n  notes string\n  // Additional fields\n  authentication_consistency bool?\n  authentication_notes string?\n  authentication_details string?\n}\n\nclass Discrepancy {\n  type string\n  documentation_said string?\n  api_testing_showed string?\n  severity string\n  resolution string\n  // For website portals\n  area string?\n  phase1_claim string?\n  phase2_finding string?\n}\n\nclass ExecutiveSummary {\n  total_endpoints_discovered int\n  total_datasets int?\n  total_files int?\n  accessible_endpoints int\n  protected_endpoints int?\n  broken_endpoints int?\n  success_rate string\n  primary_formats string[]\n  authentication_required bool\n  estimated_scraper_complexity ComplexityLevel\n  // Collation fields\n  improvements_from_run1 map<string, string>?\n}\n\nclass DataCatalog {\n  total_files_discovered int\n  total_endpoints int\n  file_formats map<string, int>\n  data_categories string[]\n  downloadable_files map<string, string>[]\n}\n\nclass ScraperRecommendation {\n  type ScraperType\n  confidence ConfidenceLevel?\n  rationale string[]\n  complexity ComplexityLevel\n  estimated_effort string\n  key_challenges string[]\n}\n\nclass CollationMetadata {\n  collation_timestamp string\n  run1_timestamp string\n  run2_timestamp string\n  validation_report string\n  runs_compared int\n  collation_agent string\n}\n\nclass CollationAnalysis {\n  run_comparison map<string, string>\n  improvements_from_run2 string[]\n  discrepancies_resolved map<string, string>[]\n  consistency_checks map<string, string>\n}\n\nclass ValidatedSpec {\n  source string\n  source_type string\n  timestamp string\n  url string\n  executive_summary ExecutiveSummary\n  validation_summary ValidationSummary\n  authentication AuthenticationSpec?\n  access_requirements AccessRequirements?\n  endpoints EndpointDetails[]\n  data_catalog DataCatalog?\n  scraper_recommendation ScraperRecommendation\n  discrepancies Discrepancy[]\n  artifacts_generated string[]\n  next_steps string[]\n  // Collation-specific fields\n  collation_metadata CollationMetadata?\n  collation_analysis CollationAnalysis?\n}\n\n// ============================================================================\n// Validation Report Types (from ba-validator.md)\n// ============================================================================\n\nclass ValidationResult {\n  confidence float @description(\"Confidence in the phase result (0.0-1.0)\")\n  identified_gaps string[] @description(\"List of gaps or issues found\")\n  recommendations string[] @description(\"Recommendations for improvement\")\n  validation_notes string @description(\"Detailed validation notes\")\n}\n\nclass PhaseValidation {\n  status ValidationOverallStatus\n  issues map<string, string>[]\n  notes string\n}\n\nclass CriticalGap {\n  gap_type string\n  description string\n  action_required string\n  // Additional fields\n  discovered int?\n  documented int?\n  missing int?\n}\n\nclass ValidationReport {\n  validation_timestamp string\n  input_file string\n  overall_status ValidationOverallStatus\n  overall_confidence float @description(\"Overall confidence between 0.0 and 1.0 (validated: must be >= 0.0 and <= 1.0)\")\n  phase_validations map<string, PhaseValidation>\n  critical_gaps CriticalGap[]\n  recommendations_for_second_pass string[]\n  validation_summary string\n}\n\n// ============================================================================\n// Collation Report Types (from ba-collator.md)\n// ============================================================================\n\nclass CollationResult {\n  collation_complete bool\n  final_spec_path string\n  final_confidence_score float @description(\"Final confidence score between 0.0 and 1.0 (validated: must be >= 0.0 and <= 1.0)\")\n  total_endpoints int\n  endpoints_run1 int\n  endpoints_run2 int\n  improvements_count int\n  discrepancies_resolved int\n  consistency_rate string\n  ready_for_scraper_generation bool\n}\n",
}

def get_baml_files():
    return _file_map
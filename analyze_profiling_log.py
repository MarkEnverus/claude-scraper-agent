#!/usr/bin/env python3
"""Analyze profiling logs to identify performance bottlenecks.

This script parses logs generated by the @profile_time decorator and generates
a comprehensive timing report showing where time is spent during BA Analyzer execution.

Usage:
    python analyze_profiling_log.py profiling_output.log

Example output:
    ================================================================================
    PERFORMANCE ANALYSIS REPORT
    ================================================================================

    ### PHASE TIMINGS ###
    Phase 0: Detection: 12.34s (1.0%)
    Phase 1: Documentation: 45.67s (3.8%)
    Phase 2: Testing: 958.50s (80.3%)
    Phase 3: Validation: 176.89s (14.9%)
    TOTAL: 1193.40s

    ### ENDPOINT TESTING ###
    Total endpoints tested: 115
    Average time per endpoint: 8.33s
    Min: 5.20s
    Max: 12.45s
    Total time in endpoint testing: 958.50s (80.3% of total)

    ### ITERATIVE DISCOVERY ###
    Pages visited: 5
    Average time per page: 2.47s
    Total time: 12.34s

    ### ANTHROPIC API CALLS ###
    Total API calls: 120
    Average time per call: 4.15s
    Total time in API calls: 498.00s (41.7% of total)
"""

import re
import sys
from collections import defaultdict
from pathlib import Path


def analyze_profiling_log(log_file: str) -> None:
    """Parse profiling log and generate timing report.

    Args:
        log_file: Path to profiling log file
    """
    if not Path(log_file).exists():
        print(f"Error: Log file not found: {log_file}")
        sys.exit(1)

    phase_times = {}
    endpoint_times = []
    page_times = []
    api_times = []
    botasaurus_times = defaultdict(list)

    print(f"Analyzing profiling log: {log_file}")
    print()

    with open(log_file) as f:
        for line in f:
            # Phase timings
            if match := re.search(r'\[PERF\] (Phase \d+: \w+) - DONE in ([\d.]+)s', line):
                phase_name = match.group(1)
                duration = float(match.group(2))
                phase_times[phase_name] = duration

            # Endpoint timings
            if match := re.search(r'\[PERF\] Endpoint \d+/\d+: .+ - ([\d.]+)s', line):
                endpoint_times.append(float(match.group(1)))

            # Page visit timings
            if match := re.search(r'\[PERF\] Iterative discovery page \d+: ([\d.]+)s', line):
                page_times.append(float(match.group(1)))

            # API call timings
            if match := re.search(r'\[PERF\] Anthropic API call: ([\d.]+)s', line):
                api_times.append(float(match.group(1)))

            # Botasaurus operation timings
            if match := re.search(r'\[PERF\] (Botasaurus: [^-]+) - DONE in ([\d.]+)s', line):
                operation_name = match.group(1)
                duration = float(match.group(2))
                botasaurus_times[operation_name].append(duration)

    # Generate report
    print("=" * 80)
    print("PERFORMANCE ANALYSIS REPORT")
    print("=" * 80)

    # Phase timings
    if phase_times:
        print("\n### PHASE TIMINGS ###")
        total_time = sum(phase_times.values())

        # Sort by phase number
        sorted_phases = sorted(phase_times.items(), key=lambda x: x[0])
        for phase, duration in sorted_phases:
            pct = (duration / total_time * 100) if total_time > 0 else 0
            print(f"{phase}: {duration:.2f}s ({pct:.1f}%)")

        print(f"TOTAL: {total_time:.2f}s ({total_time/60:.1f} minutes)")

        # Identify bottleneck phase
        bottleneck_phase = max(phase_times.items(), key=lambda x: x[1])
        print(f"\nðŸ” BOTTLENECK: {bottleneck_phase[0]} ({bottleneck_phase[1]:.2f}s, {bottleneck_phase[1]/total_time*100:.1f}%)")
    else:
        print("\n### PHASE TIMINGS ###")
        print("âš ï¸  No phase timing data found")
        total_time = 0

    # Endpoint testing
    if endpoint_times:
        print(f"\n### ENDPOINT TESTING ###")
        total_endpoint_time = sum(endpoint_times)
        avg_time = total_endpoint_time / len(endpoint_times)

        print(f"Total endpoints tested: {len(endpoint_times)}")
        print(f"Average time per endpoint: {avg_time:.2f}s")
        print(f"Min: {min(endpoint_times):.2f}s")
        print(f"Max: {max(endpoint_times):.2f}s")
        print(f"Total time in endpoint testing: {total_endpoint_time:.2f}s", end='')

        if total_time > 0:
            pct = (total_endpoint_time / total_time * 100)
            print(f" ({pct:.1f}% of total)")

            # Estimate potential speedup with parallelization
            if len(endpoint_times) > 1:
                # Assume 5x speedup with parallel requests (conservative)
                parallel_speedup = 5
                parallel_time = total_endpoint_time / parallel_speedup
                time_saved = total_endpoint_time - parallel_time
                new_total = total_time - time_saved

                print(f"\nðŸ’¡ OPTIMIZATION OPPORTUNITY:")
                print(f"   Parallelizing endpoint testing (5x speedup):")
                print(f"   - Current: {total_endpoint_time:.2f}s")
                print(f"   - Parallel: {parallel_time:.2f}s")
                print(f"   - Time saved: {time_saved:.2f}s ({time_saved/60:.1f} min)")
                print(f"   - New total time: {new_total:.2f}s ({new_total/60:.1f} min)")
        else:
            print()

    # Iterative discovery
    if page_times:
        print(f"\n### ITERATIVE DISCOVERY ###")
        total_page_time = sum(page_times)
        avg_page_time = total_page_time / len(page_times)

        print(f"Pages visited: {len(page_times)}")
        print(f"Average time per page: {avg_page_time:.2f}s")
        print(f"Total time: {total_page_time:.2f}s", end='')

        if total_time > 0:
            pct = (total_page_time / total_time * 100)
            print(f" ({pct:.1f}% of total)")
        else:
            print()

    # Anthropic API calls
    if api_times:
        print(f"\n### ANTHROPIC API CALLS ###")
        total_api_time = sum(api_times)
        avg_api_time = total_api_time / len(api_times)

        print(f"Total API calls: {len(api_times)}")
        print(f"Average time per call: {avg_api_time:.2f}s")
        print(f"Total time in API calls: {total_api_time:.2f}s", end='')

        if total_time > 0:
            pct = (total_api_time / total_time * 100)
            print(f" ({pct:.1f}% of total)")
        else:
            print()

    # Botasaurus operations
    if botasaurus_times:
        print(f"\n### BOTASAURUS OPERATIONS ###")

        for operation, times in sorted(botasaurus_times.items()):
            total_op_time = sum(times)
            avg_op_time = total_op_time / len(times)
            count = len(times)

            print(f"{operation}:")
            print(f"  - Called: {count} times")
            print(f"  - Average: {avg_op_time:.2f}s")
            print(f"  - Total: {total_op_time:.2f}s", end='')

            if total_time > 0:
                pct = (total_op_time / total_time * 100)
                print(f" ({pct:.1f}% of total)")
            else:
                print()

    # Summary
    print("\n" + "=" * 80)
    print("SUMMARY")
    print("=" * 80)

    if not phase_times:
        print("âš ï¸  No profiling data found in log file")
        print("   Ensure you ran the analyzer with --debug flag and @profile_time decorators are active")
        return

    # Overall assessment
    if total_time > 900:  # > 15 minutes
        print("âš ï¸  Analysis took over 15 minutes - performance optimization recommended")
    elif total_time > 600:  # > 10 minutes
        print("âš ï¸  Analysis took over 10 minutes - consider optimization")
    else:
        print("âœ… Analysis completed in reasonable time")

    # Recommendations
    print("\nðŸ“‹ RECOMMENDATIONS:")

    if endpoint_times and len(endpoint_times) > 10:
        endpoint_pct = (sum(endpoint_times) / total_time * 100) if total_time > 0 else 0
        if endpoint_pct > 50:
            print(f"   1. Endpoint testing is the bottleneck ({endpoint_pct:.1f}% of time)")
            print(f"      â†’ Parallelize endpoint testing with asyncio.gather() or ThreadPoolExecutor")
            print(f"      â†’ Potential speedup: 5-10x (estimated new runtime: {total_time/5/60:.1f}-{total_time/10/60:.1f} min)")

    if api_times:
        api_pct = (sum(api_times) / total_time * 100) if total_time > 0 else 0
        if api_pct > 30:
            print(f"   2. LLM API calls are significant ({api_pct:.1f}% of time)")
            print(f"      â†’ Consider batching requests or using parallel calls where possible")
            print(f"      â†’ Optimize prompts to reduce tokens/response time")

    if page_times and len(page_times) > 10:
        print(f"   3. Iterative discovery visited {len(page_times)} pages")
        print(f"      â†’ Consider adding max_pages limit (e.g., 10-15 pages)")

    print("\n" + "=" * 80)


if __name__ == "__main__":
    if len(sys.argv) != 2:
        print("Usage: python analyze_profiling_log.py <log_file>")
        print("Example: python analyze_profiling_log.py profiling_output.log")
        sys.exit(1)

    analyze_profiling_log(sys.argv[1])
